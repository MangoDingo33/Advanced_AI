{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, SimpleRNN, LSTM\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from scipy import stats  # 과학용 계산 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _linnerrud_dataset:\n",
      "\n",
      "Linnerrud dataset\n",
      "-----------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20\n",
      "    :Number of Attributes: 3\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "The Linnerud dataset is a multi-output regression dataset. It consists of three\n",
      "exercise (data) and three physiological (target) variables collected from\n",
      "twenty middle-aged men in a fitness club:\n",
      "\n",
      "- *physiological* - CSV containing 20 observations on 3 physiological variables:\n",
      "   Weight, Waist and Pulse.\n",
      "- *exercise* - CSV containing 20 observations on 3 exercise variables:\n",
      "   Chins, Situps and Jumps.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  * Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris:\n",
      "    Editions Technic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_linnerud\n",
    "\n",
    "linnerud = load_linnerud()\n",
    "print(linnerud.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[  5., 162.,  60.],\n",
       "        [  2., 110.,  60.],\n",
       "        [ 12., 101., 101.],\n",
       "        [ 12., 105.,  37.],\n",
       "        [ 13., 155.,  58.],\n",
       "        [  4., 101.,  42.],\n",
       "        [  8., 101.,  38.],\n",
       "        [  6., 125.,  40.],\n",
       "        [ 15., 200.,  40.],\n",
       "        [ 17., 251., 250.],\n",
       "        [ 17., 120.,  38.],\n",
       "        [ 13., 210., 115.],\n",
       "        [ 14., 215., 105.],\n",
       "        [  1.,  50.,  50.],\n",
       "        [  6.,  70.,  31.],\n",
       "        [ 12., 210., 120.],\n",
       "        [  4.,  60.,  25.],\n",
       "        [ 11., 230.,  80.],\n",
       "        [ 15., 225.,  73.],\n",
       "        [  2., 110.,  43.]]),\n",
       " 'feature_names': ['Chins', 'Situps', 'Jumps'],\n",
       " 'target': array([[191.,  36.,  50.],\n",
       "        [189.,  37.,  52.],\n",
       "        [193.,  38.,  58.],\n",
       "        [162.,  35.,  62.],\n",
       "        [189.,  35.,  46.],\n",
       "        [182.,  36.,  56.],\n",
       "        [211.,  38.,  56.],\n",
       "        [167.,  34.,  60.],\n",
       "        [176.,  31.,  74.],\n",
       "        [154.,  33.,  56.],\n",
       "        [169.,  34.,  50.],\n",
       "        [166.,  33.,  52.],\n",
       "        [154.,  34.,  64.],\n",
       "        [247.,  46.,  50.],\n",
       "        [193.,  36.,  46.],\n",
       "        [202.,  37.,  62.],\n",
       "        [176.,  37.,  54.],\n",
       "        [157.,  32.,  52.],\n",
       "        [156.,  33.,  54.],\n",
       "        [138.,  33.,  68.]]),\n",
       " 'target_names': ['Weight', 'Waist', 'Pulse'],\n",
       " 'frame': None,\n",
       " 'DESCR': '.. _linnerrud_dataset:\\n\\nLinnerrud dataset\\n-----------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20\\n    :Number of Attributes: 3\\n    :Missing Attribute Values: None\\n\\nThe Linnerud dataset is a multi-output regression dataset. It consists of three\\nexercise (data) and three physiological (target) variables collected from\\ntwenty middle-aged men in a fitness club:\\n\\n- *physiological* - CSV containing 20 observations on 3 physiological variables:\\n   Weight, Waist and Pulse.\\n- *exercise* - CSV containing 20 observations on 3 exercise variables:\\n   Chins, Situps and Jumps.\\n\\n.. topic:: References\\n\\n  * Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris:\\n    Editions Technic.\\n',\n",
       " 'data_filename': 'linnerud_exercise.csv',\n",
       " 'target_filename': 'linnerud_physiological.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linnerud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chins</th>\n",
       "      <th>Situps</th>\n",
       "      <th>Jumps</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Waist</th>\n",
       "      <th>Pulse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Chins  Situps  Jumps  Weight  Waist  Pulse\n",
       "0     5.0   162.0   60.0   191.0   36.0   50.0\n",
       "1     2.0   110.0   60.0   189.0   37.0   52.0\n",
       "2    12.0   101.0  101.0   193.0   38.0   58.0\n",
       "3    12.0   105.0   37.0   162.0   35.0   62.0\n",
       "4    13.0   155.0   58.0   189.0   35.0   46.0\n",
       "5     4.0   101.0   42.0   182.0   36.0   56.0\n",
       "6     8.0   101.0   38.0   211.0   38.0   56.0\n",
       "7     6.0   125.0   40.0   167.0   34.0   60.0\n",
       "8    15.0   200.0   40.0   176.0   31.0   74.0\n",
       "9    17.0   251.0  250.0   154.0   33.0   56.0\n",
       "10   17.0   120.0   38.0   169.0   34.0   50.0\n",
       "11   13.0   210.0  115.0   166.0   33.0   52.0\n",
       "12   14.0   215.0  105.0   154.0   34.0   64.0\n",
       "13    1.0    50.0   50.0   247.0   46.0   50.0\n",
       "14    6.0    70.0   31.0   193.0   36.0   46.0\n",
       "15   12.0   210.0  120.0   202.0   37.0   62.0\n",
       "16    4.0    60.0   25.0   176.0   37.0   54.0\n",
       "17   11.0   230.0   80.0   157.0   32.0   52.0\n",
       "18   15.0   225.0   73.0   156.0   33.0   54.0\n",
       "19    2.0   110.0   43.0   138.0   33.0   68.0"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pd.DataFrame(linnerud.data, columns=linnerud.feature_names),\n",
    "                pd.DataFrame(linnerud.target, columns=linnerud.target_names)],\n",
    "               axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chins     0\n",
       "Situps    0\n",
       "Jumps     0\n",
       "Weight    0\n",
       "Waist     0\n",
       "Pulse     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and test test\n",
    "x = df.drop(['Pulse'], axis=1)\n",
    "y = df['Pulse']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test, y_train,y_test = train_test_split(x,y,test_size=0.15,random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 5), (3, 5), (17,), (3,))"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "std = x_train.std(axis=0)\n",
    "x_train /= std\n",
    "x_test -= mean\n",
    "x_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(5,1)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(4, activation='relu'))  # 은닉층 2\n",
    "cnn_model.add(Dense(1, activation='linear'))\n",
    "optimizer = Adam(learning_rate=0.05)\n",
    "\n",
    "# 모델 컴파일\n",
    "cnn_model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1번째 폴드 처리중"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2번째 폴드 처리중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3번째 폴드 처리중\n",
      "#4번째 폴드 처리중\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(x_train) // k\n",
    "\n",
    "num_epochs = 100\n",
    "all_mae_histories = []\n",
    "checkpoint = ModelCheckpoint(\"best_kcnn.h5\", save_best_only=True, verbose=0, monitor='val_mae')\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"#{i+1}번째 폴드 처리중\")\n",
    "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate(\n",
    "        [x_train[:i * num_val_samples],\n",
    "         x_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [y_train[:i * num_val_samples],\n",
    "         y_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    model = cnn_model\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=4, verbose=0, callbacks=checkpoint)\n",
    "    mae_history = history.history[\"val_mae\"]\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step - loss: 45.4529 - mae: 6.3285\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"best_kcnn.h5\")\n",
    "\n",
    "\n",
    "test_mse_score, test_mae_score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 모델 생성\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(64, activation='relu', input_shape=(5, 1)))  # 은닉층 1\n",
    "rnn_model.add(Dense(4, activation='relu'))  # 은닉층 2\n",
    "rnn_model.add(Dense(1, activation='linear'))\n",
    "optimizer = Adam(learning_rate=0.1)\n",
    "\n",
    "# 모델 컴파일\n",
    "rnn_model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1번째 폴드 처리중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2번째 폴드 처리중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3번째 폴드 처리중\n",
      "#4번째 폴드 처리중\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(x_train) // k\n",
    "\n",
    "num_epochs = 100\n",
    "all_mae_histories = []\n",
    "checkpoint = ModelCheckpoint(\"best_krnn.h5\", save_best_only=True, verbose=0, monitor='val_mae')\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"#{i+1}번째 폴드 처리중\")\n",
    "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate(\n",
    "        [x_train[:i * num_val_samples],\n",
    "         x_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [y_train[:i * num_val_samples],\n",
    "         y_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    model = rnn_model\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=4, verbose=0, callbacks=checkpoint)\n",
    "    mae_history = history.history[\"val_mae\"]\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 187ms/step - loss: 59.0680 - mae: 6.5216\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"best_krnn.h5\")\n",
    "\n",
    "test_mse_score, test_mae_score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 생성\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(64, activation='relu', input_shape=(5, 1)))  # 은닉층 1\n",
    "lstm_model.add(Dense(4, activation='relu'))  # 은닉층 2\n",
    "lstm_model.add(Dense(1, activation='linear'))\n",
    "optimizer = Adam(learning_rate=0.1)\n",
    "\n",
    "# 모델 컴파일\n",
    "lstm_model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1번째 폴드 처리중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2번째 폴드 처리중\n",
      "#3번째 폴드 처리중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4번째 폴드 처리중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(x_train) // k\n",
    "\n",
    "num_epochs = 100\n",
    "all_mae_histories = []\n",
    "checkpoint = ModelCheckpoint(\"best_klstm.h5\", save_best_only=True, verbose=0, monitor='val_mae')\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"#{i+1}번째 폴드 처리중\")\n",
    "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate(\n",
    "        [x_train[:i * num_val_samples],\n",
    "         x_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [y_train[:i * num_val_samples],\n",
    "         y_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    model = rnn_model\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=4, verbose=0, callbacks=checkpoint)\n",
    "    mae_history = history.history[\"val_mae\"]\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 177ms/step - loss: 67.7941 - mae: 8.0143\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"best_klstm.h5\")\n",
    "\n",
    "\n",
    "test_mse_score, test_mae_score = model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
